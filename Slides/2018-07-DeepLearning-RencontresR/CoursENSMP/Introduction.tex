\chapter*{Introduction}\addcontentsline{toc}{chapter}{Introduction}\markboth{Introduction}{Introduction}La reconnaissance des formes traite dela prise de d\'ecision automatique dans des probl\`emes declassement. De nombreuses m\'ethodes de cette discipline trouvent leurs origines dans les statistiques.Ainsi des statisticiens tels que \citeasnoun{Galton1892}  et \citeasnoun{Fisher1936}se sont interess\'es \`a ce domaine,  qui ar\'eellement connu un essort important dans les ann\'ees ``soixante''pouss\'e, par le d\'eveloppement de l'informatique.  Analyse discriminante, discrimination, classement, apprentissagesupervis\'e sont autant de termes diff\'erents qui d\'esignent le probl\`eme de la reconnaissance des formes, que l'on pourraitd\'efinir de la fa\c{c}on suivante :  \begin{quote}\`A partir d'exemples de signaux complexes et de d\'ecision correctesconcernant ces signaux, apprendre \`a prendre des d\'ecisions pourdes signaux \`a venir.\end{quote}C'est une activit\'e  que nous exercons tous les jours.Ainsi nous savons gr\^ace \`a notre exp\'erience pass\'ee :\begin{itemize}\item attribuer un nom \`a un visage connu,\item distinguer une voiture d'un camion,\item reconnaitre certaines esp\`eces arbres,\item ...\end{itemize}D'un point de vue formel, ce type de probl\`eme peut s'exprimer commesuit :\begin{itemize}\item on consid\`ere des objets (individus), d\'ecrits par $p$  caract\'eristiques qui d\'efinissent un vecteur forme $\x_i$ appartenant typiquement \`a un sous-ensemble de $\R^p$ ;\item ces objets appartiennent chacun \`a une classe parmi les classes $\cal{C}_1,\cdots,\cal{C}_K$ ;\item le but est de classer un nouvel objet $\x$  dans l'une des $K$classes. \end{itemize}Souvent deux d\'ecisions suppl\'ementaires sont introduites : le doute et le rejet d'individus aberrants (``outliers'').La  d\'ecision de  doute  revient \`a se laisser la possibilit\'ede ne pas classer certains vecteurs forme. D\'ecider de classerun individu comme n'appartenant \`a aucune classe est \'equivalent \`a consid\'erer une classe  $\cal{O}$, qui contient lesindividus aberrants (typiquement des erreurs de mesure).Notons que l'\'ecole fran\c{c}aise d'analyse de donn\'ees \`a la suite deBenzecri insiste sur la distinction entre les termes classement et classification. Un probl\`eme de  classement (``classification'' en anglais !) consiste \`a affecter des individus \`a desclasses connues {\em a priori}.  En  classification (``clustering'' dans le dialect anglo-saxon), on  tente de d\'ecouvrir une structure de classes  qui soit ``naturelle'' aux donn\'ees.Dans la litt\'erature li\'ee \`ala reconnaissance des formes, la distinction entre les deux approchesest souvent d\'esign\'ee par les termes``apprentissage supervis\'e'' et ``non supervis\'e''. D'une mani\`ere g\'en\'erale, le mod\`ele de base en reconnaissance des formes prend la forme suivante :\begin{itemize}\itemextraction et s\'election    de caract\'eristiques,\itemclassement.\end{itemize}% complementarite des deux etapesLes deux \'etapes sont compl\'ementaires :si les caract\'eristiques extraites sont tr\`es discriminantes,la probl\`eme de classement devient \'evident. \`A l'inverse,si la m\'ethode de classement est ``infaillible'', elle sera \`a m\^eme de classer sur la base de n'importe quel  jeu de caract\'eristiques.En g\'en\'eral le choix des caract\'eristiques extraites est plus li\'e au probl\`eme \`a r\'esoudre que le choix de la m\'ethode de classement.% Analyse discriminante a but descriptifNotons que les techniques d'extraction de caract\'eristiques sont parfoisqualifi\'ees de discrimination \`a but descriptif \cite{Romeder1973}. En effet le but  imm\'ediat de l'extraction de caract\'eristiques n'est pas de classerde nouveaux individus mais  de d\'eterminer quelles  variables ou combinaisonsde variables caract\'erisent, d\'ecrivent, au mieux les diff\'erences entre les classes.  \begin{ex} \cite{Romeder1973} Hommes politiques et analyse linguistique :\\Soit l'ensemble des d\'eput\'es \'elus en 1881. On d\'esire discriminer deux groupes extr\^emes :\begin{itemize}\item un groupe comprenant l'extr\^eme gauche, les radicaux socialistes et lesradicaux ;\item un autre groupe compos\'e par les conservateurs, les conservateurs lib\'eraux et lesbonapartistes.\end{itemize}Il est possible de caract\'eriser les hommes politiques  par les fr\'equences de 53 mots (st\'er\'eotypes tels que ``menace, famille, dieux, r\'epublique...'') figurant dans leurs discours. Dans ce cas, le but n'est pas de deviner la tendance d'un nouveaud\'eput\'e mais plut\^ot de conna\^{\i}tre quels sont les st\'er\'eotypes, les combinaisonsde st\'er\'eotypes utilis\'es par les hommes politiques de chaque tendance. \end{ex}\begin{ex} \cite{Ripley1996}On consid\`ere un ensemble de malades atteints du syndrome de Cushing (hypers\'ecr\'etion de la glande adrenale).Trois causes possibles de la maladie sont connues. Pour chaque malade, on observe le taux de s\'ecretion urinaire (mg/24 heures) de :\begin{itemize}\item tetrahydrocortisone,\item pregnanetriol.\end{itemize}Le probl\`eme consiste a \'evaluer la cause de la maladie de nouveaux patientsdont on a mesur\'e les taux de s\'ecr\'etion urinaire.\end{ex}Il existe un grand nombre de m\'ethodes qui visent \`a r\'esoudrele probl\`eme de classement \'enonc\'e ci-dessus. Ces m\'ethodes peuvent\^etre partag\'ees en deux approches :\begin{itemize}\item {\bf approche statistique} (``sampling paradigm''), qui mod\'elise dans un premier temps les densit\'es $f_k(\x)$, propres \`a chaque classe  puis utilise les outils de la th\'eorie de la d\'ecision statistique pour aboutir \`a une classification ;\item {\bf approche discrimination} (``diagnostic paradigm''), qui vise \`a trouver directement les fonctions discriminantes, c'est \`a dire les fonctions qui permettent de d\'ecider quel individu appartient \`a quelle classe. C'est typiquement l'approche utilis\'ee en discrimination lin\'eaire ou bien par les techniquesneuronales.\end{itemize}Les deux approches ne sont pas cloisonn\'ees et sont \'equivalentesdans certaines circonstances.Dans tous les cas, le processus de classification vise \`a partitionner l'espace des  caract\'eristiques en r\'egions distinctes correspondant aux cat\'egories.Ces notes de cours visent \`a pr\'esenter un ensemble repr\'esentatif, maisnon exhaustif, des techniques les plus usuelles en reconnaissance statistique des formes. Les trois premiers chapitres pr\'esentent l'approche statistique. Le premierchapitre pose les fondements de la th\'eorie de la d\'ecision utilis\'eeen reconnaissance des formes et aborde les probl\`emes d'estimation des perfomances d'une proc\'edure de classification. Le second chapitreest consacr\'e aux m\'ethodes param\'etriques, c'est-\`a-dire aux m\'ethodesissues de l'approche statistique qui font l'hypoth\`ese que les densit\'es$f_k(\x)$ appartiennent \`a une famille donn\'ee de distributions. Le troisi\`emechapitre traite des m\'ethodes non param\'etriques qui ne posent pratiquementaucune hypoth\`ese restrictive sur la forme des distributions.Dans le chapitre quatre l'approche diagnostic est pr\'esent\'ee. L'accent est mis en particulier sur la discrimination lin\'eaireet sur les r\'eseaux de neurones \`a couches.Le cinqui\`eme chapitre introduit les m\'ethodes non supervis\'ees. Cetteapproche tient une place \`a part en reconnaissance des formes. Elletraite des probl\`emes o\`u l'on recherche une structure de classesans disposer d'exemples \'etiquett\'es. Nous concentrerons notreattention sur l'approche probabiliste en classification automatique. Enfin le dernier chapitre adresse le  probl\`eme particulier desdonn\'ees spatiales.%Partie 1 : sampling paradigm (6 heures)% 1er theorie bayesienne de la decision% 2eme apprentissage supervise et approche param\'etrique% 3eme apprentissage supervise et approche non parametrique%Partie 2 : diagnostic paradigm (2 heures)% discriminant de Fisher% discrimination lin\'eaire% reseau de neurones%Partie 3 : Apprentissage non supervise (4 heures)% classification automatique (algorithme EM)% cartes de kohonen%Partie 4 : Champ de Markov % modele, simulation... (2 heures)% segmentation supervisee et non supervisee (2 heures) 