\chapter{Donn\'ees spatiales et reconnaissance des formes}% de l'interet d'utiliser des methode particulieres .....Dans ce chapitre nous consid\'erons des vecteurs formes qui poss\`edentune localisation spatiale (par exemple la position d'un pixel dans uneimage). Les variables indiquant la position ``g\'eographique'' rev\^etent souventune importance particuli\`ere par rapport aux autres variables et doivent \^etretrait\'ees de mani\`ere distincte. Dans le contexte d'un probl\`eme de classement ou bien  de classification,il semble naturel de vouloir visualiser la partition dans l'espace g\'eographique.Si des techniques classiques de reconnaissance des formes sont utilis\'ees pourdiscriminer ou classifier, la partition obtenue sera en g\'en\'eralespatialement tr\`es morcel\'ee. Pour \'eviter ce morcellement, il faut consid\'ererl'information spatiale des donn\'ees, c'est-\`a-dire le fait que deux vecteurs forme spatialement proches tendent \`a appartenir \`a la m\^eme classe.La prise en compte des d\'ependances spatiales peut s'effectuer au niveau :\begin{itemize}\itemdu pr\'etraitement,\item du classement (ou de la classification).\end{itemize}Ce chapitre pr\'esente quelques exemples de pr\'etraitements possibles, et insistesurtout sur  les m\'ethodes de classification ou de classement qui int\'egr\`entla notion de d\'ependance spatiale. Comment int\'egrer l'information spatialedans un algorithme de reconnaissance des formes ? Il est possible de recourir au bon sens, si bien partag\'e, pour modifier certains algorithmes classiques, mais on peut aussi choisir de partir d'un mod\`ele statistique raisonnable incorporant la notion de d\'ependance spatiale. Les statistiques spatiales offrent une grande vari\'et\'e de choix de mod\`eles.Ces statistiques trouvent leurs applications dans tous lesdomaines o\`u les donn\'ees \`a traiter sont localis\'ees spatialement commeen astronomie, exploitation mini\`ere, \'ecologie,  g\'eographie etarch\'eologie... Cette branche de la statistique vise \`a r\'epondre \`ades questions aussi diverses que :\begin{itemize}\item  Comment r\'esumer un ensemble de donn\'ees spatiales par des statistiqueset des graphiques pertinents ?\item Est-ce que les arbres d'une for\^et sont r\'epartis au ``hasard'', oubien existe-t-il une structure sous-jacente  ?\item Tel mod\`ele statistique explique-t-il mieux que tel autre la r\'epartition spatiale des donn\'ees observ\'ees  ?\item Quelle temp\'erature fait-il \`a Paris, connaissant la temp\'erature de certaines villes voisines  ?\end{itemize}Suivant le type de donn\'ees consid\'er\'ees, les int\'er\^ets et lesm\'ethodes sont diff\'erents \cite{Ripley1982}. Si la localisation des individus (individu au sens de l'analyse des donn\'ees) et les distances entreindividus sont le ph\'enom\`enede premi\`ere importance, les donn\'ees analys\'ees seront des points dans l'espace. Par contre, si  des mesures localis\'eesspatialement sont la mati\`ere premi\`erede l'analyse statistique, les individus \'etudi\'es seront des vecteurs localis\'es.Dans tous les cas, l'ensemble des donn\'ees est consid\'er\'e comme lar\'ealisation d'un processus stochastique :\begin{defi}Un processus stochastique $\{\X_t\}$ est une suite de v.a. indic\'ees sur un sous-ensemble de $\R^d$.\end{defi}Souvent l'indice repr\'esente le temps. Dansle cadre des statistiques spatiales, l'indice figure les coordonn\'eesdans l'espace (la plupart du temps le plan) et la variable al\'eatoire $\X_t$peut signifier l'absence ($\X_t=0$) ou la pr\'esence ($X_t=1$) d'un point en $t$, la temp\'erature \`a l'endroit $t$... Le type de donn\'ees d\'etermine la classe de mod\`eles statistiques prisen compte. Ainsi plusieurs classes de processus peuvent \^etre distingu\'ees :\begin{itemize}\item Les processus stochastiques g\'en\'erateurs de points (Stochastic Point Processesen anglais), qui mod\'elisent la r\'epartion spatiale de points.\begin{ex}Dans le cas o\`u l'on s'int\'eresse uniquement \`a la r\'epartitionspatiale d'un ensemble d'individus (des arbres, des villes...) \`al'int\'erieur d'une zone g\'eographique d\'efinie, les processus stochastiquesg\'en\'erateurs de points  sont des mod\`eles statistiques adapt\'es.Ainsi, la premi\`ere \'etape de l'analyse consiste \`a d\'eterminer si les points sont r\'epartis au hasard ou forment une structure plus complexe.Ce probl\`eme rel\`eve de la th\'eorie des tests d'hypoth\`ese et faitintervenir le processus de Poisson :\[\begin{array}{c c}H_0: & \mbox{Les donn\'ees sont la r\'ealisation d'un processus de Poisson} \\H_1: & \mbox{Les donn\'ees ne sont pas r\'eparties au ``hasard''}\end{array} \]\end{ex}\item Les processus g\'en\'erateurs de variables r\'egionalis\'ees, qui mod\'elisent des ph\'enom\`enes spatialement continus (par exemple, la temp\'erature en France). Ce genre de processus sert essentiellementdans la th\'eorie de l'interpolation spatiale.\item Les s\'eries spatiales qui sont une sorte de g\'en\'eralisation des s\'erie temporelles, qui prennent en compte des donn\'ees localis\'ees,en un certain nombre de sites (Par exemple, la hauteur des arbres dans une for\^et).\end{itemize} Une pr\'esentation d\'etaill\'ee des processus stochastiques spatiaux peut \^etre trouv\'ee dans \citeasnoun{Cliff1981}et \citeasnoun{Ripley1981}.     Dans le cadre de la discrimination et de la classification d'un ensemblede vecteurs forme,  seules  les  variables  r\'egionalis\'ee et les  s\'eries spatiales fournissent des mod\`eles exploitables.% Introduction des notations\section{Modifications des donn\'ees}%----------------------------------------------------\subsection{Utilisation des variables spatiales}Traiter les variables de positions spatiales au m\^eme titre que les autres variables d\'ecrivant les sites, semble \^etre uneid\'ee naturelle. Les coordonn\'eesspatiales peuvent \^etre pond\'er\'ees pour contr\^olerla quantit\'e d'information spatiale qui sera prise en compte par l'algorithmede classement ou de classification automatique utilis\'e. Cette id\'ee remonte\`a \citeasnoun{Berry1966} et a aussi \'et\'e utilis\'ee en segmentationd'image par \citeasnoun{Jain1991}. D'apr\`es \citeasnoun{Oliver1989} ce genre d'approche souffre du m\^eme d\'efaut que la pr\'ec\'edente : elle tend\`a s\'eparer dans des classes diff\'erentes deux sites qui sonttr\`es similaires mais qui sont \'eloign\'es g\'eographiquement.  \subsection{Transformation des variables}Au lieu de travailler sur le tableau individus/variables initial, il estpossible de commencer par une phase de pr\'etraitement. Cette phase depr\'etraitement a pour but d'extraire de nouvelles variables qui contiennent l'information spatiale.\begin{ex}Une possibilit\'e consiste \`a d\'efinir une taille de fen\^etre g\'eographiqueet \`a remplacer les variables initiales d'un vecteur forme par une combinaison lin\'eairedes variables de ce vecteur forme et de ses voisins g\'eographiques (c.-\`a-.d., \`a l'int\'erieur de la fen\^etre centr\'ee sur cet individu).\end{ex}\subsection{Utilisation de la matrice des distances spatiales}%-----------------------------------------------------------Si les donn\'ees initiales prennent la forme d'un tableau de distances individu/individu, on peut transformer cette matrice pour int\'egrer l'informationspatiale.\citeasnoun{Oliver1989} proposent d'utiliser les distancesg\'eographiques $g_{ij}$ entre les sites $i$ et $j$ pour modifierles distances ou dissimilarit\'es $d_{ij}$ calcul\'ees avecles variables non g\'eographiques. Il r\'esulte de cetteop\'eration que la m\'ethode de classification utilis\'ee,part d'une nouvelle matrice de dissimilarit\'e $D^*=\{d^*_{ij}\}$qui m\'elange informations g\'eographiques et non g\'eographiques.Les algorithmes de classification usuels (non contraints) partitionnentles donn\'ees. \begin{ex}\cite{Oliver1989}Partant d'une matrice de dissimilarit\'es $D=\{d_{ij}\}$, la d\'emarche suivante fournit une partition des donn\'ees qui \'evite un trop grand morcellement g\'eographique sans toutefois produiredes classes totalement connexes :\begin{itemize}\item  Modification de la matrice des dissimilarit\'es : \[d^*_{ij}=d_{ij}\cdot [1-\exp{(-g_{ij}/W)}]\]avec $W$ un coefficient arbitraire. Plus $W$ est grand, plusla nouvelle matrice des dissimilarit\'es $D^*$ est influenc\'eepar les distances g\'eographiques et moins la partition sera fragment\'ee.\item Transformation de la matrice $D^*$ en un tableau individus/variablespar une analyse factorielle.\item Partitionnement du nouveau tableau de donn\'ees par l'algorithme desk-means. \end{itemize}% Mentionner la CAH\end{ex}    \section{Classification hi\'erarchique contrainte}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Au cours d'un processus de classification agglom\'eratif, il est possible de  restreindre les regroupement aux entit\'es qui sontg\'eographiquement voisines. Les contraintes de contigu\"{\i}t\'esont alors respect\'ees de fa\c{c}on absolue et les classes produitessont connexes, c'est \`a dire qu'une classe forme une seule r\'egiong\'eographique, un seul bloc \cite{Legendre1987,Lebart1978,Openshaw1977}.Ces proc\'edures de classification rangent dans des classes s\'epar\'eesdeux sites qui sont spatialement tr\`es \'eloign\'es m\^eme s'ilssont tr\`es similaires au niveau des variables non g\'eographiques. L'information spatiale joue alors un r\^ole pr\'epond\'erant.Ce genre d'approche n'autorise pas la variation de  ``la quantit\'ed'information spatiale'' utilis\'ee dans le processus de classification.Produire des classes g\'eographiquement connexes exigede d\'efinir au pr\'ealable quel individu est spatialement voisin de quel autre.La d\'{e}finition des rapports de voisinage est \'{e}quivalente \`{a} la constructiond'un graphe non orient\'{e} o\`{u} chaque n{\oe}ud est un \'{e}l\'{e}ment del'ensemble des donn\'{e}es et chaque ar\^{e}te figure une relation de voisinage.Une classification automatique avec contrainte de contigu\"{\i}t\'e absolue peut\^{e}tre partag\'{e}e en deux \'{e}tapes: \begin{enumerate}\item La d\'{e}finition d'un graphe de voisinage. Ceci peut \^{e}tre r\'{e}alis\'{e} parune triangulation de Delaunay, par un graphe de Gabriel, par une grille...\item La classification avec contraintes. Il est possible de modifier certainsalgorithmes classiques pour respecter les contraintes r\'{e}sum\'{e}es par le graphe.\end{enumerate}  \begin{ex}\cite{Lebart1978}La classification hi\'erarchique ascendante est une m\'ethode de classificationsimple et utilisable pour des ensembles de donn\'ees de taille raisonnable(moins de 10000 individus).L'ajout de contraintes spatiales peut se faire de mani\`ere naturelle :\begin{itemize}\item {\bf Initialisation :} calcul du graphe de voisinage et des distances entreindividus deux \`a deux (Chaque individu est consid\'er\'e comme une classe).\item {\bf It\'erer :} tant que le nombre de classes est sup\'erieur \`a un :\begin{itemize}\item regrouper les deux classes qui sont les plus proches au sens d'uncertain crit\`ere d'agr\'egation parmi les classes voisines au sensdu graphe de voisinage,\item recalculer la matrice des distances et le graphe de voisinageentre les nouvelles classes.\end{itemize}\end{itemize}Le fait de chercher seulement parmi les voisins g\'eographiques quellessont les classes  les plus proches r\'eduit de beaucoup l'espace de recherche etacc\'el\`ere la proc\'edure. \end{ex}% Remarque sur l'algo de Fisher (lire l'article)\section{Discrimination lin\'eaire et corr\'elation spatiale}% Bouquin de MAclachlan%%%Pour prendre en compte la continuit\'e spatialed'une image, dans le contexte de la  discrimination, \citeasnoun{Switzer1980} proposede consid\'erer des vecteurs formes augment\'es $(\x_1^+,\cdots,\x_N^+)$\`a la place des vecteurs forme initiaux $(\x,\cdots,\x_N) $. La pr\'esentation plus g\'en\'erale de \citeasnoun{Mardia1984} d\'efiniele vecteur forme augment\'e $\x_i^+$ comme$$\x_i^+=(\x_i^t,\x_{G_i}^t)^t,$$avec $\x_{G_i}$ le vecteur forme constitu\'e par les $s$ vecteurs voisins de $\x_i$ :$$\x_{G_i}=(\x_{i1},\cdots,\x_{is})^t.$$Dans le but de rendre possible l'expression d'une fonction discriminante lin\'eaire,les hypoth\`eses suivantes sont faites :\begin{itemize}\item chaque vecteur forme observ\'e $\x_i$ est la somme d'un vecteur moyenne et d'un bruit gaussien $\epsilon_i$ :$$\x_i= \sum_{k=1}^K c_{ik} \bmu_k + \epsilon_i,$$     \item le bruit $\epsilon_1,\cdots,\epsilon_N$ est  multi-gaussien de moyenne nulle (identique pour toute les classes).\itemon suppose une corr\'elation spatiale intrins\`eque :$$cov \left[ \X_i, \X_j  \right ] = \rho(d)\bSigma, $$o\`u $d$ est la distance s\'eparant $\X_i$ et $\X_j$. Notonsque $\rho(0)=1$.\itemon suppose une tr\`es forte continuit\'e spatiale : si un pixel $\x_i$ appartient \`a la classe $k$ alors ses voisins appartiennent\`a la m\^eme classe avec une probabilit\'e proche de 1. \end{itemize}Ainsi  sous toutes ces hypoth\`eses on peut d\'eterminer la forme des vecteur moyenneset matrice de covariance des vecteurs formes augment\'es :\begin{itemize}\item$$\bmu_k^+= \E \left[ \X_i^+  | \X_i \in {\cal C}_k \right]= \boldmath{1}_{s+1} \otimes \bmu_k$$o\`u $\boldmath{1}_{s+1}$ est est vecteur colonne de dimension $s+1$ (s est le nombre devoisins)\item$$\bSigma^+ = \bC \otimes \bSigma$$o\`u $\bC$ est la matrice de corr\'elation spatiale entre le composante de $\x_i^+$. Sataille est donc de $(s+1)\times(s+1)$. \end{itemize}Pour construire les fonctions discriminantes, on suppose que les vecteurs augmentent\'es $\x_i^+$ d'une classe $k$ suivent une loi multi-gaussiennede vecteur moyenne $\bmu_k^+$ et de matrice de variance $\bSigma^+$. Cette hypoth\`ese Gaussienne homosc\'edastique am\`ene \`a consid\'erer desfonctions discriminantes lin\'eaires.  \section{Approche globale}Pour traiter des donn\'ees non spatiales, les mod\`eles statistiques utilis\'esdans le contexte de la discrimination ou de la classification supposent que les vecteurs forme sont ind\'ependants : la loijointe d'un ensemble de vecteurs forme donn\'e est le produitdes densit\'e de chaque vecteur forme.Une mani\`ere d'aborder le probl\`eme,en introduisant la notion de d\'ependance spatiale, consiste \`a fairedes hypoth\`eses directement sur la forme de la loi jointe. Dans ce sensce type d'approche peut \^etre qualifi\'e de global. La mod\'elisation statistique globale des images pour la segmentationsuppose l'existence de deux champs al\'eatoires. L'image observ\'ee,$\x$, est la r\'ealisation d'un premier champ al\'eatoire $\X=\{ \X_s,s \in S\}$  et l'image segment\'ee, $\bc$, estla r\'ealisation d'un second champ $\bC=\{ \bC_s,s \in S\}$ (avec $S$, l'ensemble des pixels).Les variables al\'eatoires $\X_s$ prennent leur valeur dans $\R^d$ et les $\bC_s$ dans un ensemble fini $\Omega=\{\omega_1,\cdots,\omega_K \}$ avec $K$ le nombrede classes. Le mod\`ele consid\`ere que $\X$ est une observation bruit\'ee de $\bC$.Ainsi une relation existe entre les deux champs :\begin{equation}\label{eq:relation}\X=R(\bC,\N),\end{equation}o\`u $\N$ est le bruit.Le probl\`eme de la segmentation supervis\'e (classement) consiste \`a trouverun estimateur $\hat{\bc}$ de $\bc$ lorsque l'on dispose d'exemple d'imagessegment\'ees ou bien de zones segment\'ees dans une image. La segmentation nonsupervis\'ee est concern\'ee par le probl\`eme plus d\'elicat d'estimation $\hat{\bc}$ en l'absence d'exemple de segmentation. Comme dans le cas des donn\'ees non spatiales la th\'eorie bay\'esienne de lad\'ecision permet de d\'efinir un cadre formel \`a ces  probl\`emes.Notons\begin{itemize}\item  $P(\X=\x | \bC=\bc)$ la loi des donn\'ees conditionnelle \`a la connaissancedu champ $\bc$,\item la loi {\em a priori} $P(\bC=\bc)$ sur l'image segment\'ee,\item le co\^ut $L(\bc,\hat{\bc}(\x))$ associ\'e \`a la d\'ecision $\hat{\bc}(\x)$sachant que $\bC=\bc$.\end{itemize}Notons que la distribution de probabilit\'e $P(\X | \bC)$ est d\'etermin\'eepar la relation qui existe entre les champs $\X$ et $\bC$ (Equation \ref{eq:relation}).La  distribution a posteriori peut  \^etre exprim\'ee par le th\'eor\`eme de Bayes :\[P(\bC=\bc | \X=\x)=\frac{P(\bC=\bc) P(\X=\x | \bC=\bc) }{P(\X=\x)}\]La strat\'egie bay\'esienne consiste alors \`a  prendrela d\'ecision qui minimise  le risque conditionnel :\[\hat{\bc}= arg \min_{\bc} R( \bc | \x)\]avec\[R( \bc | \x)=\E \left[ L(\Z, \bc)|\x \right ] =\sum_{\z}  L(\z, \bc) P(\bC=\z | \X=\x),\]o\`u $L(\z, \bc)$ est le co\^ut de dire que l'image segment\'ee est $\bc$ lorsque l'image segment\'ee est en fait $\z$. Deux fonctions de co\^utsont couramment utilis\'ees en analyse d'image :\begin{itemize}\item $L(\z, \bc)=\II_{\{\bc \neq \z \}}$, c'est le co\^ut ``0--1'' qui vaut 0 pour labonne d\'ecision et 1 pour une mauvaise d\'ecision. Dans ce cas l'estimateurde $\bc$ est le maximum a posteriori (MAP) :\[\hat{\bc}= arg\max_{\bc} P( \bC=\bc | \x)\]\item $L(\z, \bc)=\sum_{s \in S} \II_{\{\bc_s \neq \z_s \}}$, qui consid\`ere non plusl'image dans son int\'egralit\'e mais le nombre de pixels bien class\'es. Dansce cas l'estimateur est celui qui maximise les probabilit\'es marginales a posteriori (MPM) \cite{Marroquin1987}:\[\hat{\bc_s}= arg\max_{\bc_s} P( \bC_s=\bc_s | \x), \ \forall s \in S.\]\end{itemize}Cette approche globale du probl\`eme de segmentation partage des probl\`emescommuns avec la reconnaissance statistique des formes classique, mais sedistingue de plusieurs mani\`eres. Ainsi comme en reconnaissance statistiquedes formes, il est n\'ecessaire de r\'epondre aux questions suivantes :\begin{enumerate}\item Quel  mod\`ele relatif aux donn\'ees observ\'ees adopter ($P(\X | \bC)$) ?\item Comment estimer les param\`etres du mod\`ele choisi ?\end{enumerate}Les probl\`emes particuliers soulev\'es par cette approche sont les suivants :\begin{itemize}\itemComment mod\'eliser les connaissances a priori sur la structure de l'image segment\'ee ($P(\bC)$) ? En effet, dans le cas de donn\'ees non spatiales cette  probabilit\'e est simplement une loi multinomiale,ce qui ne semble pas du tout adapt\'e pour la prise en comptedes d\'ependances spatiales.\itemComment trouver l'estimateur de l'image segment\'ee quiminimise la fonction de co\^ut choisie ? Concernant les donn\'eesnon spatiales, lorsque les param\`etres de la loi {\em a posteriori}sont d\'etermin\'es, l'optimisation du risque conditionnel est direct(pour le co\^ut \{0,1\}), ce qui est loin d'\^etre le cas pourl'approche globale d\'ecrite pr\'ec\'edemment.  \end{itemize}Notons aussi que \`a la diff\'erence de la reconnaissance statistique des formes classique qui raisonne sur un \'echantillonde taille $N$, l'approche globale dispose le plus souvent d'une seule image(ou jeu de donn\'ees) et donc d'un \'echantillon de taille 1.Les m\'ethodes globales de segmentation  r\'esolvent souvent le probl\`emedu choix de mod\`ele en utilisant les champs de Markov utilis\'es en statistique spatiale.\section{S\'eries spatiales : mod\`eles markoviens}Dans le cas o\`u le processus $\{\X_t\}$ est d\'efini en un certain nombrede sites sp\'ecifiques, et prend ses valeurs sur un ensemble discretou continu, il existe des mod\`eles, qui poss\`edent beaucoup de points communs avec les s\'eries temporelles. Ces mod\`eles, comme dans le cas des processus g\'en\'erateurs de points, sontdes alternatives \`a l'hypoth\`ese d'absence d'autocorr\'elation spatiale \cite{Ord1982}.La classe de mod\`eles la plus r\'epandue  dans ce contexte est repr\'esent\'ee par les champs al\'eatoires de Markov.\subsubsection{Champs al\'eatoires de Markov}Les cha\^{\i}nes de Markov sont des processus stochastiques les plussimples pour tenir compte de la non ind\'ependance des v.a. $\X_n$ parrapport \`a un indice discret $n$ :\begin{defi}Un processus stochastique $\{\X^n: n=1,2,...\}$ prenant ses valeursdans un espace fini est une cha\^{\i}ne de Markov sila r\'ealisation de $\X^n$ sachant toutes les r\'ealisations pass\'eesne d\'epend que de la derni\`ere valeur prise :\begin{equation}P(\X^n=\x^n | \X^{n-1}=\x^{n-1},...,\X^{1}=\x^{1})=P(\X^n=\x^n | \X^{n-1}=\x^{n-1}).\end{equation}  \end{defi}Ce concept de d\'ependance markovienne  peut \^etre \'etendu de biendes mani\`eres. Les champs de Markov sont une extension de lanotion de d\'ependance markovienne pour des processus stochastiques dont l'indice appartient \`a un espace multidimensionel et plus seulement \`a unsous-ensemble de $\R$.  Deux cas sont \`a distinguer :\begin{itemize}\item les champs de Markov dont l'indice varie de fa\c{c}on continue ;\item les champs de Markov dont l'indice est discret.\end{itemize}Les premiers trouvent leur domaine d'application en physique th\'eorique etles seconds servent entre autre de mod\`eles pour les statistiques ayant un caract\`erespatial. Seul le second cas sera examin\'e dans ce document.  % Besoin d'un notion de voisinageSi l'indice n'appartient pas \`a un sous ensemble de $\R$ mais \`a un sous ensemble de $\R^d$, les notions de pass\'e et de futur par rapport\`a un indice $t$ ne tiennent plus, et il faut recourir au concept plus g\'en\'eral de voisinage.%Definition d'un systeme de voisinage\begin{defi} \cite{Geman1984}Soit $S=\{ s_1,s_2,...,s_N\}$ un ensemble d'indices (dans un contexte de mod\'elisationspatiale, l'indice repr\'esente les coordonn\'ees d'un site). $G=\{G_s, s \in S \}$ un ensemblede parties de $S$ est un syst\`eme de voisinage pour $S$ si, et seulement si,$\forall r,s \in S$,\begin{enumerate}\item $s\not \in G_s$,\item $s \in G_r \Leftrightarrow r\in G_s$.\end{enumerate}\end{defi}Notons que $\{S,G\}$ est un graphe. % Definition d'une cliqueUn autre concept utile li\'e \`a la notion de syst\`eme de voisinageest celui de clique :\begin{defi}Soit $G$ un syst\`eme de voisinage sur un ensemble de sites $S$, une clique $c$ estun sous-ensemble de $S$ tel que tous les \'el\'ements de $c$ soientvoisins les uns des autres au sens de $G$.\end{defi}% Deux types de grillesL'ensemble des indices (des sites) d'un graphe de voisinageforme un r\'eseau. On distingueles r\'eseaux \`a mailles r\'eguli\`eres et les r\'eseaux \`a mailles irr\'eguli\`eres. Les premiers sont utilis\'es pour mod\'eliserla distribution d'une population (v\'eg\'etale, animale...) \'echantillonn\'ee de mani\`ere tr\`es r\'eguli\`ere lors d'une exp\'erience.Les  seconds sont utilis\'es pour d\'ecrire la r\'epartition naturelled'une population. \begin{ex}Toutes les communes composant un d\'epartement sont caract\'eris\'eespar des nombres li\'es \`a leur activit\'e agricole. L'activit\'eagricole ne semble pas ind\'ependante de la localisation d'une commune etil semble judicieux de mod\'eliser la r\'epartition spatiale de cetteactivit\'e par un champ de Markov. L'ensemble $S$ des indicespeut \^etre choisi comme les coordonn\'ees  du centre de lacommune et deux communes sont consid\'er\'ees comme voisines si elles partagent une fronti\`ere commune. Les mailles de ce r\'eseau sont irr\'eguli\`eres.\end{ex}  Lorsque les relations de voisinage ne sont pas d\'efinies demani\`ere explicite et si les sites ne sont pas r\'epartisr\'eguli\`erement, il faut d\'efinir pr\'ecis\'ement la notion de voisinage avant de pouvoir recourir \`a une mod\'elisationmarkovienne. Une solution possible consiste \`a dessiner une tesselation deVorono\"{\i}, et dire que deux sites sont voisins si leurs polygones de Vorono\"{\i} respectifs partagent un c\^ot\'e commun.\begin{defi}Soit $S$ un ensemble d'indices muni d'un syst\`eme de voisinage $G$ et$\X=\{ \X_s,s \in S\}$ une famille de variables al\'eatoires prenant leurs valeurs sur  $\Omega$. $\X$ est un champ de Markovpar rapport \`a $G$ si :\begin{enumerate}\item $P(\X=\x)>O, \forall \x \in \Omega$ ;\item $P(\X_s=\x_s | \X_r, r\neq s)=P(\X_s=\x_s | \X_r, r \in G_s),\forall s\in S.$\end{enumerate}\end{defi}% Equivalence Gibbs-MarkovCette d\'efinition affirme que l'\'etat d'un site ne d\'epend que desvoisins imm\'ediats de ce site, mais elle n'est pas directement utilisableen pratique pour d\'efinir un champ de Markov sans la connaissance du th\'eor\`emed'Hammersley-Clifford d\'emontr\'e en 1971 :\begin{th}Soit $\X=\{ \X_s,s \in S\}$ un champ de Markov sur un r\'eseau $S$ de$n$ sites, munid'un syst\`eme de voisinage. La distribution de probabilit\'e du champ$\X$ est une distribution de Gibbs:\[\pi(\x)=P(\X=\x)=\frac{1}{Z(T)}e^{-E(\x)/kT},\]\begin{itemize}\item o\`u $Z(T)$ est une constante de normalisation, appel\'ee constante de partition. Dans lecas o\`u $\X$ prend ses valeurs sur un ensemble fini :$$Z(T)=\sum_{\x} e^{-E(\x)/kT}.$$\item et surtout o\`u la fonction d'\'energie $E$ est de la forme:\[E(\x)=\sum_{1\leq i \leq n} x_i G_i(x_i)+      \sum \sum_{1\leq i<j\leq n}x_i x_j G_{i,j}(x_i,x_j)+      \cdots + x_1 x_2 \cdots x_n G_{1,2,\cdots,n}(x_1 x_2 \cdots x_n),\]telle que pour tout $1\leq i <j \cdots <s\leq n$, la fonction $G_{i,j,\cdots,s}$peut \^etre non nulle si et seulement si les sites $i,j,\cdots,s$ forment une clique. \end{itemize}\end{th}Notons que la constante de partition est dans la grande majorit\'e des cas incalculable (c'est une somme sur toutes les images possibles), et que la fonction d'\'energie peut s'exprimer de mani\`ere plus simple comme unesomme de fonction sur les cliques ${\cal C}$ :$$E(\x)=\sum_{\cal C} V_{\cal C}(\x).$$\subsection{Un mod\`ele binaire}Comme le fait observer \citeasnoun{Besag1974}, dans le cas o\`u les variables dechaque site sont binaires, les fonctions $G$ peuvent \^etre remplac\'eespar de simple param\`etres sans perte de g\'en\'eralit\'e. Si on se limiteaux cliques de un et deux sites, la fonction d'\'energie consid\'er\'ee aurala forme suivante:\begin{equation}E(\x)=\sum_{i=1}^N \alpha_i x_i + \sum_{i=1}^N \sum_{j \in G_i, i<j} \beta_{i,j} x_i x_j\end{equation}et la probabilit\'e conditionnelle d'avoir $X_i=x_i$ sachant la r\'ealisationde tous les voisins sera simplement:\begin{equation}P(X_i=x_i | X_j, j \neq i)=\frac{\exp{(x_i(\alpha_i+\sum \beta_{i,j} x_j))}}{1+\exp{(\alpha_i+\sum \beta_{i,j} x_j)}}\end{equation}% Exemple du modele d'Ising\begin{ex}\cite{Billoire1992}Le mod\`ele de champ de Markov le plus connu trouve son origine enm\'ecanique statistique. Il s'agit du mod\`ele d'Ising invent\'e en 1925pour expliquer certaines propri\'et\'es des ferromagn\'etiques. Les variables$X_s$ (qui repr\'esentent la valeur du 'spin' d'un atome) peuvent prendre deux valeurs$+1$ ou $-1$, et sont associ\'ees aux sites d'un r\'eseau hypercubique $S$ munid'un syst\`eme de voisinage. \`A l'\'equilibre, la probabilit\'e que le syst\`emesoit dans une configuration $\x$ est une distribution de Gibbs de fonctiond'\'energie :\begin{equation}E(\x)=\alpha \sum_{s \in S} x_s  +  \beta \sum_{r,s \in S/ r \ et \ s \ voisins} x_s x_r,\end{equation}avec $\alpha$ et $\beta$ des param\`etres mesurant respectivement lechamp magn\'etique ext\'erieur et les forces de liaison.Lorsque $\alpha=0$ (pas de champ ext\'erieur)  et que la temp\'erature est grande toutes les configurationsdeviennent \'equiprobables et lorsque la temp\'erature est basse deuxconfigurations dominent : celle o\`u tous les spins valent $+1$ et celleo\`u tous les spins valent $-1$. A basse temp\'erature le syst\`eme restepi\'eg\'e dans l'un des deux \'etats et met tr\`es longtemps \`a en sortir.Ceci explique le ph\'enom\`ene d'aimantation r\'emanente. \end{ex}\subsection{Le mod\`ele de Strauss (1977)}Le mod\`ele de Strauss peut \^etre consid\'er\'ecomme une g\'en\'eralisation du mod\`ele d'Ising, dans le caso\`u les variables prennent des valeurs discr\`etes. Dans le cas isotrope, la distribution de Gibbs est d\'efinie par lafonction d'\'energie :  \begin{equation}E(\x)=  \beta \sum_{r,s \in S/ r \ et \ s \ voisins} \II_{\{\x_s=\x_r\}}.\end{equation}Cette fonction d'\'energie compte le nombre de paires de sites voisins quiont la m\^eme valeur. Elle est maximum si les variables de tousles sites prennent une m\^eme valeur. \subsection{Des mod\`eles gaussiens}\label{sec:modelgaussien}Dans de nombreux cas, il est raisonnable de mod\'eliser la distributionjointe des sites (ou plut\^ot d'une certaine variable en chaque site)par une loi normale multidimensionnelle. Dans cette optique, deuxapproches sont possibles :\begin{itemize}\item l'approche simultan\'ee dite SAR (Simultaneous Autoregression) ;\item l'approche conditionnelle dite CAR (Conditional Autoregression).\end{itemize} La premi\`ere solution d\'efinit le processus par $N$ \'equations auto-r\'egressives simultan\'ees :\begin{equation}X_i=\mu_i + \sum \beta_{i,j} (X_j-\mu_j)+\epsilon_i, \end{equation}o\`u $\epsilon_i \sim {\cal N}(0,\sigma^2)$ \cite{Besag1974}.Cette d\'efinition correspond \`a la distribution de probabilit\'esuivante :\begin{equation}P(\X=\x)=(2\pi\sigma^2)^{\frac{-1}{2}N} det(\bB)   exp\{\frac{-1}{2\sigma^2}(\x-\bmu)^T\bB^T \bB(\x-\bmu)\},\end{equation}o\`u $\bmu$ est un vecteur de taille $N$ contenant les moyennes $\mu_i$ de tous les sites, et $\bB$ une matrice $N \times N$ inversible qui contientdes 1 sur la diagonale et les terme $-\beta_{i,j}$ partout ailleurs.La deuxi\`eme approche d\'efinit le mod\`ele de mani\`ere  conditionnelle,$$\E(\X_i | X_j=x_j, j\neq i)=\mu_i + \sum \beta_{i,j} (x_j-\mu_j).$$et $$var(\X_i | X_j=x_j, j\neq i)=\sigma^2.$$Dans ce cas la densit\'e du champ gaussien s'\'ecrit :\begin{equation}P(\X=\x)=(2\pi\sigma^2)^{\frac{-1}{2}N} det(\bB)^{\frac{1}{2}}  exp\{\frac{-1}{2\sigma^2}(\x-\bmu)^T\bB(\x-\bmu)\}.\end{equation}\subsection{Application \`a la segmentation}Si le mod\`ele de l'image est un champ de Markov, alors la distribution des donn\'ees,les probabilit\'es a priori et a posteriori sont des distributionsde Gibbs d\'efinies de la fa\c{c}on suivante :\begin{eqnarray*}& P(\x | \bc)    & \propto \exp{-U^r(\x,\bc,\Phi)}\\& P(\bc)         & \propto \exp{-U^a(\bc,\beta)}\\& P(\bc | \x)    & \propto \exp{\{-U^a(\bc,\beta)-U^r(\x,\bc,\Phi)\}}\\\end{eqnarray*}  o\`u $\Phi$ et $\beta$ sont les param\`etres des distributions. L'\'energie $U^a$ est relative aux informations a priori \`a propos de l'imagesegment\'ee $\bc$. Plus $\bc$ respecte les informations a priori et plus $U^a$ est petite. L'\'energie $U^r$ est dite \'energie de rappel aux donn\'ees, c'estpar son interm\'ediaire que la relation entre les champs $\X$ et $\bC$ estmod\'elis\'ee. \begin{ex}\label{ex:modele}Au cours de l'\'etude d'une c\'eramique qui contient des grains de carbure de silicium, on veut d\'eterminer le pourcentage de carburede silicium contenu dans le mat\'eriau.Une m\'ethode possible est de prendre une photo d'une surface de ce mat\'eriau puis d\'eterminer quelle surface est couverte par lesgrains de carbure de silicium. Le rapport entre cette surface etla surface totale donne une approximation du pourcentage cherch\'e.La photo est num\'eris\'ee et l'image r\'esultante est cod\'ee en 256niveaux de gris. La premi\`ere \'etape de l'analyse consiste donc \`asegmenter l'image en deux classes, c'est-\`a-dire distinguer les pixelsqui repr\'esentent le carbure de silicium du  reste. Formellement, on peut noter que  $\bC_s$ (la v.a. indiquant la classe)prend ses valeurs dans $\{0,1\}\times \{0,1\}$ ($\bC_s=[0 1]^t$ indique que le site$s$ appartient \`a la premi\`ere classe).Deux pixels voisins ont plus de chance d'appartenir  \`a la m\^emeclasse que deux pixels quelconques. Cette information a priori peut\^etre mod\'elis\'ee par le mod\`ele d'Ising qui est une distribution de Gibbs de fonction d'\'energie :\begin{equation}U^a(\bc)= - \beta \sum_{r,s \in S/ r \ et \ s \ voisins} \bc_s \cdot \bc_r.\end{equation}Si l'on consid\`ere que l'image observ\'ee est une d\'egradation del'image segment\'ee telle qu'en chaque pixel $x_s$ de la classe $k$ le bruit est  gaussien de moyenne $\bmu_k$ et de variance $1/\Phi$, l'\'energiede rappel aux donn\'ees est :\begin{equation}U^r(\x,\bc,\beta)=-\Phi \sum_{s \in S} (x_s - \sum_{k=1}^K c_{sk} \bmu_k)^2\end{equation}\end{ex} Les informations sur les relations entre les champs  $\X$ et $\bC$ et les a priori sur la forme du champ $\bC$ peuvent  \^etre associ\'ee \`a des \'energies.L'\'energie de la distribution a posteriori est dans ce cas la sommede toutes ces \'energies :\begin{equation}U=\sum  U_i= U^a + U^r\end{equation}Si la traduction des connaissances {\em a priori} dans uneformulation markovienne semble assez ais\'ee, l'estimationdes param\`etres du mod\`ele et la segmentation de l'imageconstituent des probl\`emes d\'elicats.\subsection{Minimisation du risque conditionnel et simulation}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%            le probleme obtention du MAP, MPM : constante Z%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Dans cette section, les param\`etres des mod\`eles (loi a priori et loisur les donn\'ees) sont suppos\'es connus.Dans ce contexte, l'approche bay\'esienne du probl\`eme de segmentation cherche\`a trouver une image segment\'ee qui  minimise le risque conditionnel.Si  la fonction de co\^ut $\{0 , 1 \}$ est  utilis\'ee,cela revient \`a chercher l'image la plus probable au sensde la distribution {\em a posteriori} (estimateur du MAP). Dans le casou cette distribution {\em a posteriori} est une distributionde Gibbs, il est en pratique impossible d'obtenir le MAP de mani\`ere analytique. De la m\^eme mani\`ere, si la fonction de co\^ut utilis\'ee consid\`ere le nombre de pixels mal class\'es, l'approchebay\'esienne revient \`a chercher l'image segment\'eedans laquelle les pixels sont mal class\'es avec uneprobabilit\'e minimale (estimateur du MPM), et cetteimage ne peut pas s'obtenir directement. Dans les deux cas, la minimisation du risque conditionnel (crit\`ere du MAP  ou du MPM) n\'ecessite l'utilisation d'algorithmesd'optimisation. L'approche la plus courante consiste \`a utiliser des m\'ethodes de Monte Carlo associ\'ees \`a des proc\'edures derecuit simul\'e \cite{Geman1984}. Notons que l'estimateur du MAPpeut aussi \^etre obtenu par des algorithmes d\'eterministes. En effettrouver l'estimateur du MAP revient \`a maximiser l'\'energie de la distribution de Gibbs {\em a posteriori}.Le premier probl\`eme qui se pose dans le cas d'utilisation desm\'ethodes de Monte Carlo est celui de la simulation d'imagesdistribu\'ees suivant la loi {\em a posteriori}. Le principe detoutes les m\'ethodes existantes consiste \`a chercherune cha\^\i ne de Markov \`a \'etat sur $E$, l'ensemble detoutes les images segment\'ees, irr\'eductible et ap\'eriodique,d'\'etat stationnaire limite unique $P(\bc | \x)$. En d'autre terme, si l'on note $\{ \bC^n : n=1,2,\cdots \}$ cette cha\^\i ne de Markov  sur $E$, on a :$$\lim_{n\rightarrow \infty} P(\bC^n = \bc | \bC^0 = \bc^0, \ \x )= P(\bc | \x)$$%\subsubsection{Cha\^\i ne de Markov homog\`ene et simulation}%Soit $E$, l'ensemble de toutes les images (d'une taille donn\'ee)%segment\'ees possibles, et $P(\bc | \x)$, une loi de probabilit\'e%sur cet ensemble, que nous noterons de mani\`ere plus concise $\pi(\bc)$.%Soit $\{ \bC_n : n=1,2,\cdots \}$ une cha\^\i ne de Markov homog\`ene sur $E$ :%$$%P(\bC_n = \bc | \bC_{n-1} = \bc')=P(\bc | \bc').%$$%$\pi$ est dite {\em invariante} si%$$%\forall \bc \in E, \ \sum_{\bc' \in E}\pi(\bc') \cdot P(\bc | \bc')= \pi(\bc)%$$%La propri\'et\'e d'invariance de %Remarquons que trouver $\pi$ la loi stationnaire d'une chaine de Markov%n'est pas une tache simple.  %$\pi$ est dite reversible si %$$%\forall (\bc,\bc') \ \pi(\bc) \cdot P(\bc' | \bc )=\pi(\bc') \cdot P(\bc | \bc' ) %$$%Cette propri\'et\'e de reversibilit\'e est int\'eressante car elle implique%l'invariance. \subsubsection{Algorithme de M\'etropolis}M\'etropolis a propos\'e un algorithme dont chaque it\'eration prend la formesuivante :\begin{enumerate}\item choix initial d'une image segment\'ee $\bc^0$,\item \`a l'it\'eration $n$ : \begin{itemize}\item \`a partir d'une image $\bc^n$ on tire une nouvelle image$\bc^{n+1}$ suivant une certaine probabilit\'e de transition.Cette probabilit\'e devant \^etre sym\'etrique :$Q(\bc^n | \bc^{n+1}) = Q(\bc^{n+1} | \bc^n)$.Une strat\'egie consiste par exemple \`a s\'electionner al\'eatoirementun pixel $i$ dans l'image $\bc^n$, puis \`a faire le choix d'un nouvel \'etat $k$ pour ce pixel. L'\'etatest tir\'e au hasard parmi les $K$ possibles suivant une loiuniforme. $\bc^{n+1}$ la nouvelle image est  identique \`a $\bc^n$sauf \'eventuellement au pixel $i$ ;\item Calcul du rapport :$$\frac{P(\bc^{n+1} | \x)}{P(\bc^{n} | \x)}=r$$ \item Si la nouvelle image est plus probable que l'ancienne ($r \geq 1$)alors on effectue la transition $\bc^n \rightarrow \bc^{n+1}$. Si la nouvelleimage est moins probable que l'ancienne ($r<1$), alors on g\'en\`ere un nombre $u$ suivant une distribution uniforme entre $0$ et $1$ et on effectue la transition $\bc^n \rightarrow \bc^{n+1}$ si $u \leq r$.De mani\`ere plus concise, $\bc^n$ est remplac\'e par $\bc^{n+1}$ avecune probabilit\'e $p=\min(1,r)$.   \end{itemize}\end{enumerate}Notons que le calcul du rapport $r$ ne fait pas intervenir la constante $Z$et l'on peut montrer \cite{Besag1974} que :$$r=\frac{P(\bc_i^{n+1} | \bc_{G_i}^{n+1}, \x )}{P(\bc_i^{n} | \bc_{G_i}^{n}, \x )}$$avec ${G_i}$ d\'enotant les pixels voisins de $i$. En r\'esum\'e, l'algorithme de M\'etropolis simule une cha\^{\i}ne de Markov \`a\'etat sur $E$ dont la matrice  de  transition $P$ est d\'efinie par$$P_{cc'}=\left \{\begin{array}{l l}Q_{cc'} \cdot \frac{P(\bc'|  \x)}{P(\bc |  \x)} & \mbox{si $P(\bc' | \x) < P(\bc | \x) $}\\Q_{cc'} & \mbox{si $P(\bc' | \x) \geq P(\bc | \x) $ et $\bc' \neq \bc$}\\1-\sum_{c' : \ c'\neq c }P_{cc'} & \mbox{si $\bc=\bc'$} \end{array}\right .  $$ La matrice de transition $Q=\{Q_{cc'}\}$ est choisit sym\'etrique.On peut montrer que $P$ sera irr\'eductible d\'es que $Q$ le sera.Comme $P$ est r\'eversible :$$P(\bc | \x ) P_{cc'}= P(\bc' | \x) P_{c'c}   $$La loi limite de la chaine sera bien la loi que l'on d\'esire simuler.\subsubsection{Dynamique d'\'echange des spins}La dynamique d'\'echange des spins\cite{Cross1983} est une version de l'algorithme de M\'etropolis qui simule une chaine irr\'eductiblesur un sous ensemble de $E$. L'image initiale $\bc^0$ d\'eterminele sous ensemble de $E$ dans lequel \'evoluera l'image. Seule l'ensemble des images ayant le m\^eme nombre de pixels dans le m\^eme\'etat  que $\bc^0$ sont accessible par la chaine de Markov simul\'eepar la dynamique d'\'echange de spins. La sp\'ecificit\'e de la dynamique des spins r\'eside dans laconstruction de l'image $\bc^{n+1}$ \`a partir de l'image $\bc^n$ :deux pixels $i$ et $j$ de $\bc^n$ sont choisis al\'eatoirement eton \'echange la valeur de leur r\'ealisation pour cr\'eer $\bc^{n+1}$.On comprend ais\'ement que ce type d'\'echange n'autorise pas l'obtentiond'image o\`u le nombre de pixel dans un certain \'etat est diff\'erentde celui de l'image initiale.La transition $\bc^n \rightarrow \bc^{n+1}$ est accept\'e suivant le principe de M\'etropolis.\subsubsection{\'Echantillonneur de Gibbs}La simulation d'image par \'echantillonneur de Gibbs a \'et\'e propos\'e par \citeasnoun{Geman1984}. Cette m\'ethode d\'efinit un ordrede visite des pixels et it\`ere de la mani\`ere suivante : \begin{enumerate}\item choix initial d'une image segment\'ee $\bc^0$,\item \`a l'it\'eration $n$ : \begin{itemize}\item un pixel $i$ est choisi suivant l'ordre de visite,\item ${\bc_i}^{n+1}$ est tir\'e au hasard suivant la loi $P(\bc_i | \x; \bc_{G_i}^{n})$.\end{itemize}\end{enumerate} Cet \'echantillonneur de Gibbs produit une suite d'images $\bc^0,\cdots,\bc^n$. Quand$n$ est grand, on peut consid\'erer que $\bc^n$ est une r\'ealisation de$P(\bc | \x)$. De plus on a la propri\'et\'e suivante :$$\lim_{n \rightarrow \infty}\frac{1}{n} [ f(\bc^0)+ \cdots +f(\bc^n)]=\E[f(\bC)],$$avec $f$ une fonction mesurable quelconque et $\bC$ une variable al\'eatoire de loi $P(\bc | \x)$.\subsubsection{Recuit simul\'e et estimateur MAP}Si les m\'ethodes d'\'echantillonage pr\'ec\'edentes permettent d'obtenir des simulations suivant la loi souhait\'ee, elles  ne permettent  pas de d\'eterminerdirectement l'image segment\'ee qui minimise le crit\`ere du MAP ou du MPM. Dans le cas du MAP, on peut modifier les algorithmes pr\'ec\'edents en int\'egrant une proc\'edure de recuit simul\'e qui fera tendrela suite des images $\bc^n$ vers le MAP.L'id\'ee consiste \`a introduire  un param\`etre de temp\'erature$T$ dans la distribution  $P(\bc | \x)$, qui s'\'ecrit$$P(\bc | \x)=\frac{\exp(\frac{1}{T} \cdot U_{\Phi,\beta}(\bc,\x))}{Z(T)}.$$\`A chaque \'etape la temp\'erature d\'ecro\^{\i}t vers z\'ero. La convergence de l'algorithmeest d\'emontr\'ee si la temp\'erature d\'ecro\^{\i}t assez lentement. Cetted\'ecroissance lente a le d\'esavantage de demander un tr\`es grand nombre d'it\'erations avant d'obtenir un estimateur du MAP satisfaisant. \subsubsection{Algorithme ICM}Pour pallier cette lenteur, \citeasnoun{Besag1986} propose un algorithmed\'eterministe qui correspond \`a l'\'echantilloneur de Gibbs en prenant unetemp\'erature nulle d\`es le d\'epart. Chaque it\'eration de cet algorithme,baptis\'e ICM (Iterative Conditional Mode) modifie la classe d'un pixel de la fa\c{c}on suivante : $${\bc_i}^{n+1}=arg \max_{\bc_i} P(\bc_i | \x; \bc_{G_i}^{n}).$$L'algorithme ICM a l'avantage de converger en moins de 10 examensde toute l'image et de faire cro\^{\i}tre $P(\bc^n | \x)$ \`a chaqueit\'eration. Le principal inconv\'enient de l'algorithme estsa forte d\'ependance par rapport aux conditions  initiales.\subsubsection{Estimateur  MPM}Une autre approche consiste \`a consid\'erer le crit\`ere du MPM.Si l'on dispose d'un certain nombre de r\'ealisations (d'images),de la loi {\em a posteriori}, alors les  probabilit\'es marginales \cite{Marroquin1993} peuvent \^etre estim\'ees . En chaque pixel $i$, la fr\'equence  empirique, $m_{ik}$, de la classe $k$ est mesur\'ee et fournit un estimation de la probabilit\'e  $P( \bC_i=k | \x)$. Ainsi on peut obtenir une segmentation de l'image, raisonnablementbonne au sens du crit\`ere MPM,  en classant  chaque pixel comme suit : \[{c_{ik}}=\left \{ \begin{array}{l}1 \ si \ k=arg \max_{\ell} m_{i \ell};  \\                              \\0 \ sinon.\\\end{array}\right .\]Les r\'ealisation de la loi {\em a posteriori} peuvent \^etre obtenueen utilisant un \'echantillonneur de Gibbs, l'algorithme de M\'etropolisou bien une dynamique d'\'echange de spins.\subsection{Estimation supervis\'ee}%----------------------------------------------------------------------------Lorsque l'on dispose d'une image bruit\'ee et de l'image segment\'ee correspondante, plusieurs solutions existent pour estimer les param\`etres $(\Phi, \beta)$. En fait ce probl\`eme se d\'ecomposealors en deux sous probl\`emes de nature identiques :\begin{itemize}\itemestimer les param\`etres $\beta$ de $P(\bC=\bc)$ ; \itemestimer les param\`etres $\Phi$ de $P(\x|\bc)$ ;\end{itemize}Comme ces deux probl\`emes reviennent \`a estimer les param\`etres d'unchamp de Markov connaissant  au moins une r\'ealisation de celui ci, nous nous limiterons au premier probl\`eme.\subsubsection{Vraisemblance}Dans la majorit\'e des cas, il est impossible de calculer la vraisemblanced'un param\`etre $\beta$ donn\'e. En effet, la vraisemblance s'\'ecrit $$\ell(\beta;\bc)= \frac{ \exp{-U^a(\bc,\beta)}}{Z(\beta)} $$o\`u $Z(\beta)$ est incalculable car c'est une somme surtoutes les images segment\'ees possibles. Dans le cas auto-normal, la constante de partition est connue et calculable, et les estimateurs du maximum de vraisemblance sont exploitables. Si l'on suppose que $\bmu=0$ la vraisemblanced'un tel mod\`ele prend la forme :$$(2\pi\sigma^2)^{\frac{-1}{2}N} det(\bB)^{\frac{1}{2}}  exp\{\frac{-1}{2\sigma^2}(\x-\bmu)^T\bB(\x-\bmu)\}.$$L'estimateur du m.v. de $\sigma^2$ est donn\'e par$$\hat{\sigma}^2=N^{-1} \x \hat{\bB}\x,$$et l'estimateur de $\bB$ est obtenu en minimisant :$$-N^{-1} \ln |\bB | + \ln{(\x^t \bB \x)}$$ce qui n'est pas un crit\`ere aisement minimisable \`a cause du calcul du d\'eterminant de $\bB$.\subsubsection{Pseudo-vraisemblance}Pour contourner le probl\`eme pos\'e par la constante departition, \citeasnoun{Besag1974} propose de trouver un estimateur qui optimise un  crit\`ere calculable,la pseudo vraisemblance :\[\beta^*=arg \max_{\beta} \prod_{i \in code \ell} P_{\beta}(\bc_i |\bc_{G_i})\]o\`u $code \ell$ est un ensemble de pixels conditionnellement ind\'ependants et$\bc_{G_i}$ est le voisinage du pixel $i$. Cette m\'ethode a l'inconv\'enientde n'utiliser qu'une partie des donn\'ees. Une extension assez naturelleconsiste \`a utiliser tous les pixels m\^eme s'ils ne sont pas ind\'ependants. Soit :\[\beta^*=arg \max_{\beta} \prod_{i=1}^N P_{\beta}(\bc_i | \bc_{G_i}).\]D'apr\`es \citeasnoun{Derin1989}, ce crit\`ere donnerait des r\'esultatsplus fiables. Notons que m\^eme si la pseudo vraisemblance est facilementcalculable pour une valeur donn\'ee de $\beta$, l'obtention d'un $\beta^*$n\'ecessite souvent l'utilisation d'algorithmes d'optimisation num\'erique.\subsubsection{Gradient stochastique}\citeasnoun{Younes1988} sugg\`ere une id\'ee originale pour trouver unestimateur du maximum de vraisemblance de $\beta$. Soit $\bc_o$ l'imagesegment\'ee disponible. Une condition n\'ecessaire d'optimalit\'e est \[\nabla_{\beta} P_{\beta}(\bc_o)=0,\]pour $\beta=\hat{\beta}_{MV}$. Cette \'equation peut se mettre sousla forme :\[{U^a}'(\bc,\beta)=\E[{U^a}'(\bC)]\] o\`u ${U^a}'(\bc)$ est le gradient de l'\'energie $U^a$ par rapport auvecteur $\beta$. Une mont\'ee de gradient stochastique peut alors\^etre mis en \oe uvre pour r\'esoudre cette derni\`ere \'equation :\begin{enumerate}\item choix initial du vecteur $\beta^0$,\item \`a l'it\'eration $m$ : \begin{itemize}\item ex\'ecution d'une \'etape d'un \'echantillonneur de Gibbs qui simule$P_{\beta^m}(\bc)$; une nouvelle image $\bc^m$ est obtenue,\item calcul de \[\beta^{m+1}=\beta^m + \frac{\lambda}{m+1}[{U^a}'(\bc^{m+1})-{U^a}'(\bc_o)]\]o\`u $\lambda$ est une constante. \end{itemize}\end{enumerate} La convergence de cet algorithme est d\'emontr\'ee,mais il est bien \'evident que le maximum atteint n'est que local.\subsection{Estimation non supervis\'ee}Dans un contexte markovien, l'estimation des param\`etres dumod\`ele n\'ecessite des r\'ealisations d'images segment\'eesissues de ce mod\`ele, et la segmentation n\'ecessite laconnaissances des param\`etres du mod\`ele. Pour r\'esoudre ceprobl\`eme, de nombreuxalgorithmes de segmentation non supervis\'ee bas\'essur les champs de Markov sont des algorithmes it\'eratifsqui utilisent un principe similaire \`a celui de l'algorithme EM :\begin{enumerate}\item choix initial de  $(\beta^0, \Phi^0)$,\item \`a l'it\'eration $m$ : \begin{itemize}\itemsimulation d'une ou plusieurs images segment\'ees en utilisantle  mod\`ele de param\`etres $(\beta^{m}, \Phi^{m})$,\item estimation de $(\beta^{m+1}, \Phi^{m+1})$ en utilisant l'imageobserv\'ee et une ou plusieurs images segment\'ees obtenues aucours des it\'erations pr\'ec\'edentes.\end{itemize}\end{enumerate} Ces algorithmessont trop nombreux pour que nous les d\'etaillons tous \cite{Chalmond1989,Besag1986,Geman1984,Derin1989,Pieczinsky1994}.Nous donnerons donc un seul exemple proche des algorithmespropos\'es dans ce chapitre et qui illustrera les comparaisons num\'eriques.\citeasnoun{Chalmond1989} propose un algorithme baptis\'e EM Gibbsien qui est destin\'e \`a trouver les param\`etres d'un mod\`ele Markovienqui maximisent la pseudo vraisemblance et donne une image segment\'eesur le principe du MPM dans le cas o\`u l'on consid\`ere que le bruit est spatialement noncorr\'el\'e et que les observations sont ind\'ependantes conditionnellement\`a la connaissance des classes :$$P_{\Phi}(\x | \bc)=\prod_{i=1}^N P(\x_i | \bc_i),$$La pseudo vraisemblance s'\'ecrit alors :\[{\cal P}_{\Theta}(\bc,\x)=P_{\Phi}(\x | \bc) \cdot \prod_{i=1}^N  P_{\beta}(\bc_i | \bc_{G_i}) \]o\`u $\Theta=(\Phi,\beta)$. S'inspirant de l'algorithme EM, l'algorithme prend la forme suivante :\begin{enumerate}\item choix initial du vecteur $\theta^0$,\item \`a l'it\'eration $(m+1)$ : \begin{itemize}\item {\bf Etape E :} \begin{itemize}\itemsimulation d'une nouvelle s\'erie d'images $\bc^1,\bc^2,\cdots,\bc^{s_o},\cdots,\bc^{s_m}$  suivant la loi$P_{\Theta^m}(\bc_i | \x; \bc_j,j \neq i)$ ($s_0$ est le nombre d'it\'erations requis pour que la suite $\{ \bc^m \}$ soit en r\'egime stationnaire), \item estimation des $u_{ik}=P_{\Theta^m}( c(\x_i)=k | \x)$ (probabilit\'e que $\x_i$ appartienne \`a la classe $k$ conditionnellement \`a l'image observ\'ee) :\[u_{ik}=\frac{1}{s_m-s_0}\sum_{s=s_0}^{s_m} \II_{\{c_{ik}=1\}};\]\end{itemize}\item {\bf Etape M :} Calcul de \begin{itemize}\item $\Phi^{m+1}=arg \max_{\Phi} \E[\log P_{\Phi}(\x | \bc) | \x, \Phi^{m}]$.Dans le cas o\`u le bruit est gaussien :\begin{equation} \bmu_k^{m+1}=\frac{\sum_{i=1}^n u_{ik} }{n_k};\end{equation}\begin{equation}\bSigma_k^{m+1}=\sum_{k=1}^K \sum_{i=1}^n \frac{u_{ik} (\x_i- \bmu_k^{m+1}) (\x_i- \bmu_k^{m+1})^t}{n_k};  \end{equation}o\`u $n_k=\sum_{i=1}^n u_{ik}$.\item  Au lieu de calculer $$\beta^{m+1}=arg \max_{\beta} \E[\log \prod_{i=1}^N  P_{\beta}(\bc_i | \bc_{G_i}))  | \x, \Phi^{m+1}],$$Chalmond calcule directement les probabilit\'es $P_{\beta}(c_{ik}=1 | \bc_{G_i})$.D'apr\`es la distribution {\em a priori} $P_{\beta}(\bc)$ choisit par l'auteur, il constate que la probabilit\'e $P_{\beta}(c_{ik}=1 | \bc_{G_i})$prend un nombre fini de valeurs qui d\'ependent de la classe $k$ dusite $i$ ainsi que de la configuration du voisinage entourant ce site.En notant $P(k | j)$ la valeur de la probabilit\'e d'avoir le site $i$appartenant \`a la classe $k$, conditionnellement au voisinage $j$,Chalmond calcule les $$\hat{P}(k | j)=arg \max_{P(k | j)} \E[log  \prod_{i=1}^N  P_{\beta}(\bc_i | \bc_{G_i}))  | \x, \Phi^{m+1}].$$Notons que ces valeurs sont utilis\'ees  dans l'it\'eration E suivante pour d\'eterminerles $P_{\beta}(c_{ik}=1 | \bc_{G_i})$ qui servent \`a l'\'echantillonneur de Gibbs car \[P(c_{ik} = 1 | \x ; \bc_{G_i}) \propto P_{\Phi}(\x_i | \Phi) \cdot P_{\beta}(c_{ik}=1 | \bc_{G_i}).\]\end{itemize} \end{itemize}\end{enumerate} 